{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XKlAh7-8ViM7"
      },
      "outputs": [],
      "source": [
        "# installing open java development kit\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# getting spark package\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.0/spark-3.2.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzipping\n",
        "!tar xf spark-3.2.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# Installing findspark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing OS\n",
        "import os\n",
        "\n",
        "# setting java environment\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "\n",
        "# setting spark environment\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.2.0-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "lRQPctpyVl_p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing spark\n",
        "import findspark\n",
        "\n",
        "# initializing spark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "sh1zowvVVoSX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# creating spark session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# getting sparkcontext from spark\n",
        "sc = spark.sparkContext\n",
        "\n",
        "# print\n",
        "sc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "gG1MuODpVtnq",
        "outputId": "71335d93-59c6-49f7-c23c-fcd2ee3174db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=pyspark-shell>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://bd92c00ec92f:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the file path\n",
        "# renamed the file from graph data.csv to graph_data.csv\n",
        "path = \"/content/graph_data.csv\""
      ],
      "metadata": {
        "id": "pm08EVc7VvjJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the data as an rdd\n",
        "rdd = sc.textFile(path)"
      ],
      "metadata": {
        "id": "ocDxnuw4V_ce"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the data inside the rdd\n",
        "rdd = rdd.map(lambda x:x.split(\",\"))"
      ],
      "metadata": {
        "id": "5qeTn7mgi_cK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the values inside the rdd into integers\n",
        "rdd = rdd.map(lambda x: [int(i) for i in x])"
      ],
      "metadata": {
        "id": "7l89VQrtnBFD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tuple of (index + 1, list of neighbor node IDs) for each row in the RDD\n",
        "index_and_neighbors = rdd.zipWithIndex().map(lambda x: (x[1] + 1, x[0]))"
      ],
      "metadata": {
        "id": "f1LE42u_0kfT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to extract neighbor node IDs from a every node(row)\n",
        "def extract_neighbors(row):\n",
        "    # defining the components of the row\n",
        "    key,value = row\n",
        "\n",
        "    # intializing an empty list for neighbors\n",
        "    neighbors = []\n",
        "\n",
        "    # looping through the value part of each row\n",
        "    for index, val in enumerate(value):\n",
        "\n",
        "         # Checking if the value is equal to 1 (indicating a neighbor)\n",
        "        if val == 1:\n",
        "\n",
        "            # appending the neighbor's index + 1 to the list\n",
        "            neighbors.append(index + 1)\n",
        "\n",
        "    # returns a tuple with the node and its neighbors\n",
        "    return (key, neighbors)"
      ],
      "metadata": {
        "id": "CEcI6nQx0xGR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying the predefined function to the index_and_neighbors\n",
        "adjacency_list = index_and_neighbors.map(extract_neighbors)"
      ],
      "metadata": {
        "id": "9fQ_NJfW0gij"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "adjacency_list.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D9Wlfkn0FRS",
        "outputId": "0c664618-86af-4315-994f-a8101795d145"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, [2, 4, 5, 7, 8, 9, 12, 14, 15, 17, 18, 20, 22, 24, 25]),\n",
              " (2, [1, 4, 7, 9, 12, 15, 17, 19, 22, 24]),\n",
              " (3, [2, 4, 5, 9, 14, 15, 18, 22, 23, 25]),\n",
              " (4, [2, 3, 7, 11, 12, 14, 17, 18, 21, 23, 24]),\n",
              " (5, [3, 4, 6, 7, 8, 12, 14, 17, 18, 19, 24, 25]),\n",
              " (6, [1, 3, 4, 7, 9, 11, 12, 14, 17, 18, 21, 22, 23]),\n",
              " (7, [4, 6, 8, 9, 11, 12, 15, 18, 19, 21, 22, 25]),\n",
              " (8, [2, 4, 10, 11, 12, 13, 14, 15, 19, 22, 23, 24]),\n",
              " (9, [1, 4, 5, 8, 10, 11, 14, 16, 20, 22, 23]),\n",
              " (10, [1, 2, 4, 5, 9, 11, 13, 16, 17, 19, 22, 24, 25]),\n",
              " (11, [1, 2, 4, 7, 9, 12, 17, 18, 19, 22, 23, 24]),\n",
              " (12, [3, 4, 5, 7, 10, 11, 14, 15, 21, 22, 23]),\n",
              " (13, [1, 2, 4, 10, 11, 12, 14, 16, 17, 19, 24]),\n",
              " (14, [2, 5, 6, 8, 9, 13, 18, 19, 21, 22, 24]),\n",
              " (15, [2, 3, 4, 5, 11, 16, 18, 20, 21, 23, 25]),\n",
              " (16, [1, 2, 7, 9, 11, 12, 13, 19, 21, 22, 24]),\n",
              " (17, [2, 4, 8, 9, 14, 15, 16, 22, 24]),\n",
              " (18, [3, 4, 9, 11, 12, 14, 16, 17, 22, 25]),\n",
              " (19, [2, 11, 14, 16, 17, 22, 24]),\n",
              " (20, [2, 3, 7, 10, 15, 16, 17, 19, 22, 25]),\n",
              " (21, [3, 4, 6, 7, 9, 13, 15, 16, 19, 20, 23, 24, 25]),\n",
              " (22, [1, 2, 4, 7, 12, 14, 15, 16, 19, 23, 24]),\n",
              " (23, [3, 4, 9, 11, 12, 14, 17, 18, 22, 24]),\n",
              " (24, [4, 8, 9, 10, 13, 16, 17, 21, 23]),\n",
              " (25, [3, 4, 5, 9, 11, 12, 14, 15, 20, 21, 22, 24])]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Find all self-loops (i.e. edge between a node onto itself)"
      ],
      "metadata": {
        "id": "b3YVHEoW3d7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filtering the nodes if the node itself is present in the list of neighbors (self_looping)\n",
        "self_loops = adjacency_list.filter(lambda x: x[0] in x[1]).collect()"
      ],
      "metadata": {
        "id": "Dsmb9-yim24s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "print(\"Answer, Number of nodes with Self-loops:\", self_loops)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8ZVKyUK39JX",
        "outputId": "035d6d04-7a2b-4b68-aa89-0d2dea0cad57"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer, Number of nodes with Self-loops: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Node with the largest out-degree"
      ],
      "metadata": {
        "id": "AUguUaxW4HCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating the length of each node's neighbor list\n",
        "out_degree = adjacency_list.map(lambda x: (x[0], len(x[1])))"
      ],
      "metadata": {
        "id": "1JghVLe-pT3-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the node with highest number of out_degree\n",
        "out_degree = out_degree.reduce(lambda x, y: x if x[1] >= y[1] else y)"
      ],
      "metadata": {
        "id": "AQD1RaQD4S1i"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "print(\"Answer, Node with the largest out-degree:\", out_degree[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GddNW_na4Gkh",
        "outputId": "d01e5676-f6a0-462a-9d46-faf69f425803"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer, Node with the largest out-degree: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Node with the larges in-degree"
      ],
      "metadata": {
        "id": "rdZxF7Bi5bIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new RDD with (neighbor, 1) for each neighbor in the adjacency list\n",
        "neighbor_counts = adjacency_list.flatMap(lambda x: [(neighbor, 1) for neighbor in x[1]])"
      ],
      "metadata": {
        "id": "JP1R_-0h5f51"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using reduceByKey to count the in-degrees for each node\n",
        "in_degree = neighbor_counts.reduceByKey(lambda x, y: x + y)"
      ],
      "metadata": {
        "id": "WU-fiLj5pVLx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the node with the largest in-degree\n",
        "largest = in_degree.max(key=lambda x: x[1])"
      ],
      "metadata": {
        "id": "DgQQAb2W6BwS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print\n",
        "print(\"Answer, Node with the largest in-degree:\", largest[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So-8bcY-6DfN",
        "outputId": "05ba4418-97d3-41fa-a301-2ec5025a484c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer, Node with the largest in-degree: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Find the distribution of vertices in-degrees"
      ],
      "metadata": {
        "id": "yCyNt51X6Z10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new RDD with (neighbor, 1) for each neighbor in the adjacency list\n",
        "neighbor_counts = adjacency_list.flatMap(lambda x: [(neighbor, 1) for neighbor in x[1]])"
      ],
      "metadata": {
        "id": "epoRu2GApXJS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using countBykey to count the in-degrees for each node\n",
        "in_degree_distribution = neighbor_counts.countByKey()"
      ],
      "metadata": {
        "id": "EXAgID8I7bxb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sorting the dictionary items based on keys in ascending order\n",
        "in_degree_distribution = dict(sorted(in_degree_distribution.items()))"
      ],
      "metadata": {
        "id": "X1fesoCC72Vh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the sorted in-degree distribution\n",
        "print(\"the distribution of vertices in-degrees:\")\n",
        "for node, count in in_degree_distribution.items():\n",
        "    print(f\"Node {node}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWwwi_5f73ix",
        "outputId": "ec2e0eef-9982-4a18-9896-40f571b497f6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the distribution of vertices in-degrees:\n",
            "Node 1: 8\n",
            "Node 2: 14\n",
            "Node 3: 10\n",
            "Node 4: 20\n",
            "Node 5: 8\n",
            "Node 6: 4\n",
            "Node 7: 11\n",
            "Node 8: 7\n",
            "Node 9: 15\n",
            "Node 10: 6\n",
            "Node 11: 14\n",
            "Node 12: 14\n",
            "Node 13: 6\n",
            "Node 14: 15\n",
            "Node 15: 11\n",
            "Node 16: 11\n",
            "Node 17: 13\n",
            "Node 18: 10\n",
            "Node 19: 12\n",
            "Node 20: 5\n",
            "Node 21: 9\n",
            "Node 22: 18\n",
            "Node 23: 11\n",
            "Node 24: 16\n",
            "Node 25: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Find a path between node 1 to node 9 [output: a list of nodes that connects 1 and 9]"
      ],
      "metadata": {
        "id": "CiOI6ygt9Xw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to find a path\n",
        "def finding_path_breadth(rdd_of_nodes, start_node, target_node):\n",
        "\n",
        "    # creating a set to keep track of visited codes\n",
        "    visited = set()\n",
        "    queue = [(start_node, [start_node])]\n",
        "\n",
        "    # while loop so that the loop continues as long as there are nodes in the queue to explore\n",
        "    while queue:\n",
        "\n",
        "        # popping the first node and it's path\n",
        "        (node, path) = queue.pop(0)\n",
        "\n",
        "        # If the current node matches the target node, return the path\n",
        "        if node == target_node:\n",
        "            return path\n",
        "\n",
        "        # If the current node hasn't been visited, mark it as visited by adding it to the set\n",
        "        if node not in visited:\n",
        "            visited.add(node)\n",
        "\n",
        "            # finding the neighbors of the current node by filtering the graph RDD\n",
        "            neighbors = rdd_of_nodes.filter(lambda x: x[0] == node).first()[1]\n",
        "\n",
        "            # for each neighbor, if it hasn't been visited, add it to the queue with an extended path\n",
        "            for neighbor in neighbors:\n",
        "                if neighbor not in visited:\n",
        "                    queue.append((neighbor, path + [neighbor]))\n",
        "\n",
        "    # If no path is found, return None\n",
        "    return None"
      ],
      "metadata": {
        "id": "dYFQ5xvkpYtB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calling the predefined function\n",
        "path = finding_path_breadth(adjacency_list, 1, 9)\n",
        "\n",
        "if path:\n",
        "    print(\"Answer, Path from 1 to 9:\", path)\n",
        "else:\n",
        "    print(\"Answer, No path found from 1 to 9.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG_pNdMHpanf",
        "outputId": "4a5cd99c-0072-45c9-e5ee-efffc8393061"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer, Path from 1 to 9: [1, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cbsAPRW-ANfA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}